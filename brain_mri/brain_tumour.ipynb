{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d077bd-9093-4f9b-b3f7-4f017c7a6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex1\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Define the tumor types and splits\n",
    "tumor_types = ['glioma_tumor', 'no_tumor', 'pituitary_tumor', 'meningioma_tumor']\n",
    "splits = ['Testing', 'Training']\n",
    "\n",
    "# Initialize empty lists for train and test sets\n",
    "train_set, test_set = [], []\n",
    "\n",
    "# Define a function to convert the label to a one-hot encoded tensor\n",
    "def get_label(tumor_type):\n",
    "    labels = {\n",
    "        'glioma_tumor': [1, 0, 0, 0],\n",
    "        'no_tumor': [0, 0, 0, 1],\n",
    "        'pituitary_tumor': [0, 0, 1, 0],\n",
    "        'meningioma_tumor': [0, 1, 0, 0],\n",
    "    }\n",
    "    return torch.tensor(labels[tumor_type], dtype=torch.float32)\n",
    "\n",
    "# Process each tumor type and split\n",
    "for tumor in tumor_types:\n",
    "    for split in splits:\n",
    "        dir_path = f'brain_mri/{split}/{tumor}'\n",
    "        for img_name in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, img_name)\n",
    "            img_pil = Image.open(img_path).resize((128, 128))\n",
    "            img_np = np.array(img_pil)\n",
    "            img_np = np.rollaxis(img_np, -1, 0)\n",
    "            img_tensor = torch.tensor(img_np, dtype=torch.float32)\n",
    "            label_tensor = get_label(tumor)\n",
    "            # Standardize the image\n",
    "            img_tensor = (img_tensor - 63.64) / 54.89\n",
    "            # Append to the respective dataset\n",
    "            if split == 'Training':\n",
    "                train_set.append((img_tensor, label_tensor))\n",
    "            else:\n",
    "                test_set.append((img_tensor, label_tensor))\n",
    "\n",
    "# Optionally, you can convert the lists to tuples if needed\n",
    "# train_set, test_set = tuple(train_set), tuple(test_set)\n",
    "\n",
    "# Example to verify the shape and type of the first training sample\n",
    "print(train_set[0][0].shape, train_set[0][0].dtype)  # Should print: torch.Size([3, 128, 128]) torch.float32\n",
    "print(train_set[0]A[1])  # Should print the one-hot encoded label tensor\n",
    "\n",
    "# Save the datasets if needed\n",
    "torch.save(train_set, 'train_set.pt')\n",
    "torch.save(test_set, 'test_set.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a78218-dfaa-4faf-bed2-85a9555c87d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 52612\n",
      "Output shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "#Ex2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvolutionalNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size=4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64 * 4 * 4, out_features=16)\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_number_of_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "# Instantiate the model and print the number of parameters\n",
    "model = ConvolutionalNN()\n",
    "print(\"Number of parameters:\", model.get_number_of_parameters())\n",
    "\n",
    "# Example to verify the forward pass\n",
    "input_tensor = torch.randn(1, 3, 128, 128)\n",
    "output_tensor = model(input_tensor)\n",
    "print(\"Output shape:\", output_tensor.shape)  # Should print: torch.Size([1, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5e714a-8e18-4b28-b835-286f18cef030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model number of parameters: 52612\n"
     ]
    }
   ],
   "source": [
    "#Ex3\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = ConvolutionalNN().to(device)\n",
    "\n",
    "print('model number of parameters:', model.get_number_of_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e8cc7d-ce9e-4d18-82b7-1daa2873dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader batch size: 32\n",
      "Test loader batch size: 1\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0005\n",
      "    maximize: False\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Loss function: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "#Ex4\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Assuming train_set and test_set are already defined as lists of tuples (image, label)\n",
    "# If not, you can load them from previously saved files\n",
    "# train_set = torch.load('train_set.pt')\n",
    "# test_set = torch.load('test_set.pt')\n",
    "\n",
    "# Define the DataLoaders\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "# Define the loss function\n",
    "loss_function = CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "\n",
    "# Print to verify\n",
    "print('Train loader batch size:', train_loader.batch_size)\n",
    "print('Test loader batch size:', test_loader.batch_size)\n",
    "print('Optimizer:', optimizer)\n",
    "print('Loss function:', loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1a5c1-1a25-43bd-b931-c8b975eb5044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss: 1.229, test loss: 1.506, test accuracy: 24.62%\n",
      "          \n",
      "Epoch 2: training loss: 1.035, test loss: 1.492, test accuracy: 25.63%\n",
      "          \n",
      "Epoch 3: training loss: 0.977, test loss: 1.482, test accuracy: 27.66%\n",
      "          \n",
      "Epoch 4: training loss: 0.954, test loss: 1.444, test accuracy: 31.98%\n",
      "          \n",
      "Epoch 5: training loss: 0.927, test loss: 1.440, test accuracy: 31.47%\n",
      "          \n",
      "Epoch 6: training loss: 0.920, test loss: 1.411, test accuracy: 33.50%\n",
      "          \n",
      "Epoch 7: training loss: 0.911, test loss: 1.426, test accuracy: 32.49%\n",
      "          \n",
      "Epoch 8: training loss: 0.896, test loss: 1.390, test accuracy: 36.80%\n",
      "          \n",
      "Epoch 9: training loss: 0.884, test loss: 1.367, test accuracy: 38.07%\n",
      "          \n",
      "Epoch 10: training loss: 0.881, test loss: 1.359, test accuracy: 38.83%\n",
      "          \n",
      "Epoch 11: training loss: 0.876, test loss: 1.372, test accuracy: 38.32%\n",
      "          \n",
      "Epoch 12: training loss: 0.867, test loss: 1.372, test accuracy: 36.55%\n",
      "          \n",
      "Epoch 13: training loss: 0.870, test loss: 1.360, test accuracy: 38.83%\n",
      "          \n",
      "Epoch 14: training loss: 0.856, test loss: 1.368, test accuracy: 38.32%\n",
      "          \n",
      "Epoch 15: training loss: 0.854, test loss: 1.387, test accuracy: 36.04%\n",
      "          \n",
      "Epoch 16: training loss: 0.851, test loss: 1.368, test accuracy: 39.34%\n",
      "          \n",
      "Epoch 17: training loss: 0.837, test loss: 1.346, test accuracy: 39.85%\n",
      "          \n",
      "Epoch 18: training loss: 0.835, test loss: 1.336, test accuracy: 41.62%\n",
      "          \n",
      "Epoch 19: training loss: 0.823, test loss: 1.313, test accuracy: 43.91%\n",
      "          \n",
      "Epoch 20: training loss: 0.831, test loss: 1.320, test accuracy: 43.15%\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "#Ex5\n",
    "epochs = 60\n",
    "n_samples_train = len(train_loader)\n",
    "n_samples_test = len(test_loader)\n",
    "training_loss_per_epoch, test_loss_per_epoch, test_accuracy_per_epoch = [], [], []\n",
    "best_accuracy = - torch.inf\n",
    "for epoch in range(epochs):\n",
    "    training_loss = 0\n",
    "    for data, labels in train_loader:\n",
    "        predict = model(data.to(device))\n",
    "        loss = loss_function(labels.to(device), predict)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += (loss.item() / n_samples_train)\n",
    "    test_loss, correct, total = (0, 0, 0)\n",
    "    for data, label in test_loader:\n",
    "        predict = model(data.to(device))\n",
    "        loss = loss_function(label.to(device), predict)\n",
    "        test_loss += (loss.item() / n_samples_test)\n",
    "        if torch.argmax(predict) == torch.argmax(label):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    accuracy = correct/total*100\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "    training_loss_per_epoch.append(training_loss)\n",
    "    test_loss_per_epoch.append(test_loss)\n",
    "    test_accuracy_per_epoch.append(accuracy)\n",
    "    print('''Epoch {}: training loss: {:.3f}, test loss: {:.3f}, test accuracy: {:.2f}%\n",
    "          '''.format(epoch+1, training_loss, test_loss, accuracy))\n",
    "print(f'\\n Best test accuracy: {best_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af01a4-9e92-4c9f-b36a-7a845ef13086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ex6\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "ax[0].plot(test_loss_per_epoch, c='r')\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Loss', fontsize=16)\n",
    "ax[1].plot(test_accuracy_per_epoch, c='g')\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Accuracy %', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b2109-c4fb-4979-b291-bb71a20b76d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
